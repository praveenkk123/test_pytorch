{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-to-Speech Generation using Bark Model with Intel Extension for PyTorch\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "After completing this workshop, participants will be able to:\n",
    "\n",
    "### Remember\n",
    "- List the key components of the Bark text-to-speech model\n",
    "- Recall the basic syntax for Intel Extension for PyTorch optimization\n",
    "\n",
    "### Understand\n",
    "- Explain how the Bark model converts text to speech\n",
    "- Describe the role of voice presets in audio generation\n",
    "- Interpret model inference times and performance metrics\n",
    "\n",
    "### Apply\n",
    "- Implement Intel optimizations for PyTorch models\n",
    "- Use the Bark model for text-to-speech generation\n",
    "- Configure different voice presets and parameters\n",
    "\n",
    "### Analyze\n",
    "- Compare performance between optimized and non-optimized models\n",
    "- Examine the impact of different text inputs on audio quality\n",
    "\n",
    "### Evaluate\n",
    "- Assess the quality of generated audio outputs\n",
    "- Judge the effectiveness of different optimization techniques\n",
    "\n",
    "### Create\n",
    "- Develop custom applications using the Bark model\n",
    "- Design new text inputs for optimal audio generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch intel_extension_for_pytorch transformers scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy\n",
    "import time\n",
    "from transformers import AutoProcessor, BarkModel\n",
    "from scipy.io.wavfile import write as write_wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the BarkAudioSynthesizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarkAudioSynthesizer:\n",
    "    def __init__(self, model_path='suno/bark-small'):\n",
    "        self.processor = AutoProcessor.from_pretrained(model_path)\n",
    "        self.model = BarkModel.from_pretrained(model_path)\n",
    "        \n",
    "        # Configure dtype and device\n",
    "        self.dtype = torch.float32\n",
    "        if torch.xpu.is_available():\n",
    "            self.device = torch.device('xpu')\n",
    "        else:\n",
    "            print(\"XPU not available, falling back to CPU\")\n",
    "            self.device = torch.device('cpu')\n",
    "            \n",
    "        # Move model to device and optimize\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model = self.model.to(memory_format=torch.channels_last)       \n",
    "        \n",
    "            \n",
    "    def generate_audio(self, text, voice_preset='v2/en_speaker_6', output_file='output.wav'):\n",
    "        inputs = self.processor(text, voice_preset=voice_preset)\n",
    "        inputs = {k: v.to(self.device) if hasattr(v, 'to') else v for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            try:\n",
    "                # Warmup\n",
    "                print(\"Performing warmup inference...\")\n",
    "                audio_array = self.model.generate(**inputs)\n",
    "                \n",
    "                # Actual inference\n",
    "                print(\"Generating audio...\")\n",
    "                start_time = time.time()\n",
    "                audio_array = self.model.generate(**inputs)\n",
    "                if torch.xpu.is_available():\n",
    "                    torch.xpu.synchronize()\n",
    "                inference_time = time.time() - start_time\n",
    "                \n",
    "                print(f\"Inference time: {inference_time:.2f} seconds\")\n",
    "                \n",
    "                audio_array = audio_array.cpu().numpy().squeeze()\n",
    "                sample_rate = self.model.generation_config.sample_rate\n",
    "                write_wav(output_file, sample_rate, audio_array)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error during generation: {str(e)}\")\n",
    "                raise\n",
    "            \n",
    "        return output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Different Voice Presets\n",
    "\n",
    "Let's test the model with different voice presets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devcloud\\pytorch\\chat_uv\\.venv\\Lib\\site-packages\\transformers\\models\\encodec\\modeling_encodec.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing warmup inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating audio...\n",
      "Inference time: 20.48 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing warmup inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating audio...\n",
      "Inference time: 31.62 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'female_voice.wav'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthesizer = BarkAudioSynthesizer()\n",
    "\n",
    "# Test with male voice\n",
    "synthesizer.generate_audio(\n",
    "    \"This is a test with a male voice.\",\n",
    "    voice_preset='v2/en_speaker_6',\n",
    "    output_file='male_voice.wav'\n",
    ")\n",
    "\n",
    "# Test with female voice\n",
    "synthesizer.generate_audio(\n",
    "    \"This is a test with a female voice.\",\n",
    "    voice_preset='v2/en_speaker_9',\n",
    "    output_file='female_voice.wav'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Different Text Types\n",
    "\n",
    "Let's experiment with different types of text input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing warmup inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating audio...\n",
      "Inference time: 26.98 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing warmup inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating audio...\n",
      "Inference time: 70.93 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:10000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing warmup inference...\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\n",
    "    \"Hello! This is a simple greeting.\",\n",
    "    \"1, 2, 3, 4, 5. Testing numbers.\",\n",
    "    \"Question: How does this sound as a question?\",\n",
    "    \"[laughing] This is an example with emotion!\"\n",
    "]\n",
    "\n",
    "for i, text in enumerate(test_texts):\n",
    "    synthesizer.generate_audio(\n",
    "        text,\n",
    "        voice_preset='v2/en_speaker_6',\n",
    "        output_file=f'test_{i}.wav'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis\n",
    "\n",
    "Let's measure the inference time for different text lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {\n",
    "    'short': \"Hello.\",\n",
    "    'medium': \"This is a medium length sentence for testing.\",\n",
    "    'long': \"This is a longer piece of text that we'll use to test how the model performs with more content. It includes multiple sentences and should take longer to process.\"\n",
    "}\n",
    "\n",
    "for length, text in texts.items():\n",
    "    print(f\"\\nTesting {length} text:\")\n",
    "    synthesizer.generate_audio(\n",
    "        text,\n",
    "        voice_preset='v2/en_speaker_6',\n",
    "        output_file=f'{length}_text.wav'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### def main():\n",
    "    # Initialize synthesizer\n",
    "    synthesizer = BarkAudioSynthesizer()\n",
    "    \n",
    "    # Get user input\n",
    "    print(\"\\nBark Audio Synthesis Menu:\")\n",
    "    print(\"1. Use preset example\")\n",
    "    print(\"2. Enter custom text\")\n",
    "    choice = input(\"Enter your choice (1 or 2): \")\n",
    "    \n",
    "    if choice == '1':\n",
    "        examples = {\n",
    "            '1': {\n",
    "                'text': \"This is a simple test of the text-to-speech system.\",\n",
    "                'voice': 'v2/en_speaker_6',\n",
    "                'desc': 'Basic Test'\n",
    "            },\n",
    "            '2': {\n",
    "                'text': \"Hello! How are you doing today?\",\n",
    "                'voice': 'v2/en_speaker_9',\n",
    "                'desc': 'Greeting'\n",
    "            },\n",
    "            '3': {\n",
    "                'text': \"The quick brown fox jumps over the lazy dog.\",\n",
    "                'voice': 'v2/en_speaker_3',\n",
    "                'desc': 'Pangram'\n",
    "            },\n",
    "            '4': {\n",
    "                'text': \"One, two, three, four, five. Testing the numbers.\",\n",
    "                'voice': 'v2/en_speaker_9',\n",
    "                'desc': 'Numbers'\n",
    "            },\n",
    "            '5': {\n",
    "                'text': \"Today's weather is sunny with clear skies.\",\n",
    "                'voice': 'v2/en_speaker_6',\n",
    "                'desc': 'Weather'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(\"\\nSelect an example:\")\n",
    "        for key, value in examples.items():\n",
    "            print(f\"{key}. {value['desc']}\")\n",
    "        \n",
    "        example_choice = input(\"Enter your choice (1-5): \")\n",
    "        selected = examples.get(example_choice)\n",
    "        \n",
    "        if selected:\n",
    "            text = selected['text']\n",
    "            voice_preset = selected['voice']\n",
    "        else:\n",
    "            print(\"Invalid choice. Using default example.\")\n",
    "            text = examples['1']['text']\n",
    "            voice_preset = examples['1']['voice']\n",
    "    else:\n",
    "        text = input(\"\\nEnter the text to synthesize: \")\n",
    "        print(\"\\nAvailable voice presets:\")\n",
    "        print(\"1. v2/en_speaker_6 (Default male voice)\")\n",
    "        print(\"2. v2/en_speaker_9 (Female voice)\")\n",
    "        print(\"3. v2/en_speaker_3 (Child voice)\")\n",
    "        voice_choice = input(\"Select voice preset (1-3): \")\n",
    "        \n",
    "        voice_presets = {\n",
    "            '1': 'v2/en_speaker_6',\n",
    "            '2': 'v2/en_speaker_9',\n",
    "            '3': 'v2/en_speaker_3'\n",
    "        }\n",
    "        voice_preset = voice_presets.get(voice_choice, 'v2/en_speaker_6')\n",
    "    \n",
    "    output_file = input(\"\\nEnter output filename (default: output.wav): \") or 'output.wav'\n",
    "    \n",
    "    # Generate audio\n",
    "    try:\n",
    "        synthesizer.generate_audio(text, voice_preset, output_file)\n",
    "        print(f\"\\nAudio generated successfully: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating audio: {str(e)}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### Knowledge and Comprehension\n",
    "- Understood the basic architecture of the Bark text-to-speech model\n",
    "- Learned how to implement Intel Extension for PyTorch optimizations\n",
    "\n",
    "### Application and Analysis\n",
    "- Successfully implemented text-to-speech generation with different voice presets\n",
    "- Analyzed performance characteristics with different input types\n",
    "- Applied optimization techniques for improved performance\n",
    "\n",
    "### Synthesis and Evaluation\n",
    "- Created a functional text-to-speech system with Intel optimizations\n",
    "- Evaluated the performance impact of different input types and optimization techniques\n",
    "\n",
    "### Best Practices\n",
    "1. Always perform a warmup inference for more accurate timing measurements\n",
    "2. Use appropriate voice presets for different types of content\n",
    "3. Consider text length and complexity when optimizing performance\n",
    "4. Implement proper error handling for production environments\n",
    "\n",
    "### Next Steps\n",
    "- Experiment with different model variants\n",
    "- Explore advanced voice customization options\n",
    "- Implement batch processing for multiple texts\n",
    "- Optimize for specific hardware configurations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
