{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28db3059-a67b-4533-8ddf-0d8e32e30e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44b3ef4657147378f560c46ea53d8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), description='Upload an image:'), Text(value='', description='Prompt:', plaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the necessary libraries for the script\n",
    "# ipywidgets for creating interactive widgets\n",
    "# IPython.display for displaying output in the notebook\n",
    "# torch for using PyTorch\n",
    "# diffusers for using the Stable Diffusion model\n",
    "# PIL for image processing\n",
    "# cv2 for image processing\n",
    "# numpy for numerical computations\n",
    "# io for handling bytes streams\n",
    "# tqdm for creating progress bars\n",
    "from ipywidgets import FileUpload, Text, Button, Output, HBox, VBox\n",
    "from IPython.display import display\n",
    "import torch\n",
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, DDIMScheduler\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a file upload widget to allow the user to upload an image\n",
    "# The image will be used as input to the Stable Diffusion model\n",
    "image_upload = FileUpload(description=\"Upload an image:\", multiple=False)\n",
    "\n",
    "# Create a text box for the user to enter a prompt\n",
    "# The prompt will be used to guide the generation of the image\n",
    "prompt_text = Text(description=\"Prompt:\", placeholder=\"Enter your prompt\")\n",
    "\n",
    "# Create a button to generate the image\n",
    "# When the button is clicked, the script will generate an image based on the uploaded image and the prompt\n",
    "generate_button = Button(description=\"Generate Image\")\n",
    "\n",
    "# Create an output widget to display the generated image\n",
    "output = Output()\n",
    "\n",
    "# Define a function to generate the image when the button is clicked\n",
    "def generate_image(b):\n",
    "    # Clear the output widget to prepare for the new output\n",
    "    with output:\n",
    "        output.clear_output(wait=True)\n",
    "        \n",
    "        # Get the uploaded image from the file upload widget\n",
    "        # The image is stored in the \"content\" attribute of the uploaded file\n",
    "        image_file = image_upload.value[0]\n",
    "        image_bytes = image_file[\"content\"]\n",
    "        \n",
    "        # Open the uploaded image using PIL\n",
    "        # The image is stored in a bytes stream, so we need to use the BytesIO class to read it\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        \n",
    "        # Resize the image to 512x512 pixels this helps with memory\n",
    "        # This is the size that the Stable Diffusion model expects\n",
    "        image = image.resize((512, 512))\n",
    "        \n",
    "        # Display the uploaded image in the output widget\n",
    "        display(image)\n",
    "\n",
    "        # Convert the image to a numpy array and apply Canny edge detection\n",
    "        # This will create a binary image with edges highlighted\n",
    "        image_array = np.array(image)\n",
    "        low_threshold = 100\n",
    "        high_threshold = 200\n",
    "        image_array = cv2.Canny(image_array, low_threshold, high_threshold)\n",
    "        image_array = image_array[:, :, None]\n",
    "        image_array = np.concatenate([image_array, image_array, image_array], axis=2)\n",
    "        canny_image = Image.fromarray(image_array)\n",
    "\n",
    "        # Get the prompt from the text box\n",
    "        user_prompt = prompt_text.value\n",
    "\n",
    "        # Load the Stable Diffusion model and control net\n",
    "        # The model is used to generate images, and the control net is used to guide the generation\n",
    "        controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\", torch_dtype=torch.float16)\n",
    "        pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "            \"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, torch_dtype=torch.float16\n",
    "        )\n",
    "        \n",
    "        # Set the scheduler for the model\n",
    "        # The scheduler is used to control the generation process\n",
    "        pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "        \n",
    "        # Move the model to the XPU\n",
    "        # This is necessary to use the model with the XPU\n",
    "        pipe = pipe.to(\"xpu\")\n",
    "\n",
    "        # Generate the image using the Stable Diffusion pipeline\n",
    "        # This will create a new image based on the uploaded image and the prompt\n",
    "        with output:\n",
    "            output.clear_output(wait=True)\n",
    "            # Create a progress bar to display the progress of the generation\n",
    "            pbar = tqdm(total=1, desc=\"Generating image\")\n",
    "            with torch.inference_mode():\n",
    "                # Generate the image\n",
    "                output_image = pipe(\n",
    "                    user_prompt, image=canny_image\n",
    "                ).images[0]\n",
    "            # Update the progress bar to indicate that the generation is complete\n",
    "            pbar.update(1)\n",
    "            # Close the progress bar\n",
    "            pbar.close()\n",
    "            # Display the generated image in the output widget\n",
    "            display(output_image)\n",
    "\n",
    "# Link the button to the generate_image function\n",
    "# When the button is clicked, the generate_image function will be called\n",
    "generate_button.on_click(generate_image)\n",
    "\n",
    "# Display the widgets in the notebook\n",
    "# The widgets include the file upload widget, the text box, the button, and the output widget\n",
    "display(VBox([image_upload, prompt_text, generate_button, output]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8653a1-7425-4a2c-acc5-3bcf42b6aa26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
